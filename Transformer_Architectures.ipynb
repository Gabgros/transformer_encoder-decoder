{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW-QXyz1fdc-"
      },
      "source": [
        "#CS 4464/7643 Deep Learning HW 3\n",
        "Transformers and Language Modeling\n",
        "In this exercise you will implement a Transformer model and several variants such as Encoder Transformers, Decoder Transformers, and Encoder-Decoder transformers.\n",
        "\n",
        "You will then use these as the basis to train a (small) Language Model from scratch on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ErpQkryF1XC",
        "outputId": "7d9075d0-a60c-4914-c590-31ad41ba97bb",
        "ExecuteTime": {
          "end_time": "2023-10-24T16:01:34.284797600Z",
          "start_time": "2023-10-24T16:00:57.164123300Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.14.6 dill-0.3.7 huggingface-hub-0.18.0 multiprocess-0.70.15\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub<0.18,>=0.16.4 (from tokenizers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.7.22)\n",
            "Installing collected packages: huggingface_hub, tokenizers\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.18.0\n",
            "    Uninstalling huggingface-hub-0.18.0:\n",
            "      Successfully uninstalled huggingface-hub-0.18.0\n",
            "Successfully installed huggingface_hub-0.17.3 tokenizers-0.14.1\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.3.1\n",
            "Collecting colab-convert\n",
            "  Downloading colab-convert-2.0.5.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting json5 (from colab-convert)\n",
            "  Downloading json5-0.9.14-py2.py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: colab-convert\n",
            "  Building wheel for colab-convert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colab-convert: filename=colab_convert-2.0.5-py3-none-any.whl size=19207 sha256=a2a13abdb5f51a652877ed1eff890d70e0fca78fe968cc60b71e4e302d1f6fda\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/9f/0a/70f4be5eeba4a3fca9d7bcf68d5a4e97edb9f22be449cc1e8c\n",
            "Successfully built colab-convert\n",
            "Installing collected packages: json5, colab-convert\n",
            "Successfully installed colab-convert-2.0.5 json5-0.9.14\n",
            "Cloning into 'gtGPT'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 10 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (10/10), 7.90 KiB | 7.90 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "#@title Colab Setup\n",
        "!pip install datasets\n",
        "!pip install tokenizers\n",
        "!pip install sacrebleu\n",
        "!pip install colab-convert\n",
        "!rm -rf gtGPT/\n",
        "!rm -rf gtgpt\n",
        "!git clone https://github.com/Helw150/gtGPT gtGPT\n",
        "!mv gtGPT/gtgpt/ .\n",
        "\n",
        "from gtgpt.utils import set_seed\n",
        "\n",
        "set_seed(3407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KhpsJ38gF5Pf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\"\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":16:8\"\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from gtgpt.model import DummyMultiHeadedSelfAttention, DummyBlock, DummyTransformer, DummyEmbedding\n",
        "from gtgpt.utils import set_seed\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.set_default_device(DEVICE)\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "setup_block = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsNegD_ghJoh"
      },
      "source": [
        "#### Embeddings\n",
        "\n",
        "We will first format our input embeddings similarly to how they are constructed in [BERT](https://arxiv.org/pdf/1810.04805.pdf).\n",
        "\n",
        "Recall from lecture that unlike a RNN, a Transformer does not inherently capture positional information in the forward pass. Because of this, we need to add a signal which encodes the position of each token in its embedding.\n",
        "\n",
        "Your first task is to implement the embedding lookup, including the addition of positional encodings. We have already provided the neccesary parameters inside of `DummyEmbedding`.\n",
        "\n",
        "```python\n",
        "self.vocab_embeddings = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "self.position_embeddings = nn.Embedding(config.block_size, config.n_embd)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3J4LRVnqF_pT",
        "ExecuteTime": {
          "end_time": "2023-10-24T16:00:29.812786300Z",
          "start_time": "2023-10-24T16:00:29.308808100Z"
        }
      },
      "outputs": [],
      "source": [
        "class Embedding(DummyEmbedding):\n",
        "    def forward(self, idx):\n",
        "        \"\"\"\n",
        "        :param idx: intTensor of shape (B,T)\n",
        "        :returns embeddings: floatTensor of shape (B,T,n_embd)\n",
        "        \"\"\"\n",
        "        B, T = idx.size()\n",
        "        embeddings = None\n",
        "        #############################################################################\n",
        "        # TODO:\n",
        "        # Implement the embedding lookup.                                           #\n",
        "        #                                                                           #\n",
        "        # This will take a few lines.                                               #\n",
        "        #############################################################################\n",
        "        token_embeddings = self.vocab_embeddings(idx)\n",
        "        positions = torch.arange(T, device=idx.device).expand(B, T)\n",
        "        position_embeddings = self.position_embeddings(positions)\n",
        "        embeddings = token_embeddings + position_embeddings\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return embeddings\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "embedding_def = In[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bFEN1m6jGeDO"
      },
      "outputs": [],
      "source": [
        "#@title Basic Embedding Test\n",
        "\n",
        "def test_embedding():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_embd = 1\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3047)\n",
        "  embedding = Embedding(config)\n",
        "  embedding.vocab_embeddings.weight = torch.nn.Parameter(torch.arange(0, 10, dtype=torch.float).reshape(10, 1))\n",
        "  embedding.position_embeddings.weight = torch.nn.Parameter(torch.arange(0, 10, dtype=torch.float).reshape(10, 1))\n",
        "  assert torch.allclose(embedding(torch.tensor([[1, 2, 3]])), torch.tensor([1, 3, 5], dtype=torch.float).reshape(1, 3, 1))\n",
        "\n",
        "test_embedding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N4g9AtKi1Es"
      },
      "source": [
        "#### 3.2 Multi-head Self-Attention\n",
        "Attention can be computed in matrix-form using the following formula:\n",
        "\n",
        "$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
        "\n",
        "We want to have multiple self-attention operations. Each of these is called a head with each head applied to some portion of the input.\n",
        "\n",
        "$head_i = Attention(W_Q X_i, W_K X_i, W_V X_i)$\n",
        "\n",
        "Here, we'll use GPT-style Multi-headed Self-Attention which fragments the head into pieces and applies one head to each fragment. The fragments are then concatenated together to reconstruct the transformed input and projected with a feed-forward layer.\n",
        "\n",
        "$MultiHead(Q, K, V) = Concat(head_1, ..., head_h)W^O$\n",
        "\n",
        "Note that while this is \"Multi-head\", all heads can be computed in parallel with a single matrix multiplication. You can find an in-depth description of this in the reference linked in the code.\n",
        "\n",
        "\n",
        "We provide the needed weights in `DummyMultiHeadedSelfAttention`\n",
        "\n",
        "```python\n",
        "# Note that we need this to be true in GPT-style MHA\n",
        "# Knowing this might come in handy :)\n",
        "assert config.n_embd % config.n_head == 0\n",
        "\n",
        "# Note: These could be a single batched linear layer\n",
        "# but we separate them for simplicity of implementation.\n",
        "self.k = nn.Linear(config.n_embd, config.n_embd)\n",
        "self.v = nn.Linear(config.n_embd, config.n_embd)\n",
        "self.q = nn.Linear(config.n_embd, config.n_embd)\n",
        "# output projection\n",
        "self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "# regularization\n",
        "self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "self.hidden_dropout = nn.Dropout(config.hidden_pdrop)\n",
        "\n",
        "self.n_head = config.n_head\n",
        "self.n_embd = config.n_embd\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wJNOQQgaGip4"
      },
      "outputs": [],
      "source": [
        "class GenericSelfAttention(DummyMultiHeadedSelfAttention):\n",
        "    def forward(self, x, attention_mask):\n",
        "        \"\"\"\n",
        "        :param x: float Tensor of shape (batch size, sequence length, embedding dimensionality)\n",
        "        :param attention_mask: int Tensor of shape (batch size, 1, sequence length, sequence_length)\n",
        "        :returns y: float Tensor of shape (batch size, sequence length, embedding dimensionality)\n",
        "        \"\"\"\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        y = None\n",
        "\n",
        "        #############################################################################\n",
        "        # TODO:                                                                     #\n",
        "        # Implement multi-headed self-attention in GPT-2 Style                      #\n",
        "        # Use the provided layers initialized in the DummySelfAttention constructor #\n",
        "        # Apply dropout to the attention values after softmax and the final output  #\n",
        "        #                                                                           #\n",
        "        # Reference:                                                                #\n",
        "        # https://jalammar.github.io/illustrated-gpt2/#part-2-illustrated-self-attention\n",
        "        #                                                                           #\n",
        "        # Note: All heads should be computed in parallel using the q,k,v layers     #\n",
        "        #                                                                           #\n",
        "        # For each item in the batch, if attention_mask[b, i, j] = 0,               #\n",
        "        # then you should manually set the attention from token i to j to be -inf   #\n",
        "        # Hint: See torch.masked_fill                                               #\n",
        "        #############################################################################\n",
        "        # Masked self-attention\n",
        "        d_k = C // self.n_head\n",
        "        queries = self.q(x).view(B, T, self.n_head, d_k).permute(0, 2, 1, 3)\n",
        "        keys = self.k(x).view(B, T, self.n_head, d_k).permute(0, 2, 1, 3)\n",
        "        values = self.v(x).view(B, T, self.n_head, d_k).permute(0, 2, 1, 3)\n",
        "\n",
        "        attention_scores = torch.matmul(queries, keys.permute(0, 1, 3, 2)) / math.sqrt(d_k)\n",
        "        attention_scores = attention_scores.masked_fill(attention_mask == 0, float('-inf'))\n",
        "        attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
        "        attention_weights = self.attn_dropout(attention_weights)\n",
        "\n",
        "        # Head concat\n",
        "        weighted_values = torch.matmul(attention_weights, values)\n",
        "        weighted_values = weighted_values.permute(0, 2, 1, 3).contiguous().view(B, T, C)\n",
        "        y = self.c_proj(weighted_values)\n",
        "\n",
        "        # Regularization\n",
        "        y = self.hidden_dropout(y)\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "\n",
        "        return y\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "mha_def = In[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "TOONbP93GrGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c473fc-c35d-4c21-f361-b67bb1d5d3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success 1\n",
            "Success 2\n"
          ]
        }
      ],
      "source": [
        "#@title Test Multi-Headed Attention\n",
        "\n",
        "def test_mha():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  config.hidden_pdrop = 0.25\n",
        "  config.attn_pdrop = 0.1\n",
        "  set_seed(3407)\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  attn = GenericSelfAttention(config)\n",
        "  attn.q.weight = torch.nn.Parameter(torch.eye(2, 2).repeat(2, 2).flip(0))\n",
        "  attn.q.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.k.weight = torch.nn.Parameter(torch.eye(2, 2).repeat(2, 2))\n",
        "  attn.k.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.v.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.v.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.c_proj.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.c_proj.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  embeddings = torch.tensor([[[1, 2, 3, 4] ,[4, 3, 2, 1]]], dtype=torch.float)\n",
        "  mask = torch.ones(1, 2, 2)\n",
        "  assert torch.allclose(attn(embeddings, mask), torch.tensor([[[5.6779, 0, 0, 0], [0, 3.0456, 4.3618, 5.6779]]], dtype=torch.float), atol=1e-3, rtol=1)\n",
        "  print(\"Success 1\")\n",
        "\n",
        "test_mha()\n",
        "\n",
        "def test_mha_mask():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  config.hidden_pdrop = 0.0\n",
        "  config.attn_pdrop = 0.0\n",
        "  set_seed(3407)\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  attn = GenericSelfAttention(config)\n",
        "  attn.v.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.v.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.c_proj.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.c_proj.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  embeddings = torch.tensor([[[1, 2, 3, 4] ,[4, 3, 2, 1]]], dtype=torch.float)\n",
        "  mask = torch.zeros(1, 2, 2)\n",
        "  mask[0, 0, 0] = 1\n",
        "  mask[0, 1, 1] = 1\n",
        "  assert torch.allclose(attn(embeddings, mask), torch.tensor([[[1, 2, 3, 4], [4, 3, 2, 1]]], dtype=torch.float), atol=1e-4)\n",
        "  print(\"Success 2\")\n",
        "\n",
        "test_mha_mask()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V-LkiiMDG0iN"
      },
      "outputs": [],
      "source": [
        "#@title Now, we can very simply create a single layer transformer block!\n",
        "class TransformerBlock(DummyBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config, GenericSelfAttention)\n",
        "\n",
        "    # A Basic Transformer Block with Attention followed by an MLP\n",
        "    # note the layer norms and residual information preserved at each step.\n",
        "    def forward(self, x, attention_mask):\n",
        "        x = x + self.attn(self.ln_1(x), attention_mask)\n",
        "        x = x + self.mlpf(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "block_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XlolMIhnfBa"
      },
      "source": [
        "#### Putting it all together\n",
        "\n",
        "Using our Embedding Layer, the above Transformer Block using our Multi-head attention, and a simple classification head we have all the pieces we need for a Transformer language model.\n",
        "\n",
        "For the forward pass, you'll want to first embed our inputs, apply each transformer layer sequentially, and finally get logits for each possible output word using a classification layer (often called a language modeling head).\n",
        "\n",
        "If an argument is passed to `hidden_cache`, you should prepend it to your input embeddings and pass it alongside the embeddings for the rest of the model. This will allow use to use this structure in Encoder-Decoder architectures later, but also allows passing vectors from any other neural network (such as a computer vision model or an audio model to enable multi-modal understanding). You can find a rich description of how these pieces come together [here](https://jalammar.github.io/illustrated-transformer/).\n",
        "\n",
        "All the parameters you'll need come from `DummyTransformer` and the code blocks above your code section.\n",
        "\n",
        "```python\n",
        "self.transformer = nn.ModuleDict(\n",
        "    dict(\n",
        "        embedding=embedding(config),\n",
        "        h=nn.ModuleList(\n",
        "            [block(config) for _ in range(config.n_layer)]\n",
        "        ),\n",
        "        ln_f=nn.LayerNorm(config.n_embd),\n",
        "    )\n",
        ")\n",
        "self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UJCBDuLzncKd"
      },
      "outputs": [],
      "source": [
        "class GenericTransformer(DummyTransformer):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config, TransformerBlock, Embedding)\n",
        "        self.block_size = config.block_size # Maximum Number of Tokens which can be encoded at once\n",
        "        self.vocab_size = config.vocab_size\n",
        "\n",
        "    def get_attention_mask(self, num_tokens):\n",
        "        \"\"\"\n",
        "        Dummy For now, we will see how we use this later!\n",
        "        \"\"\"\n",
        "        B = num_tokens.shape[0]\n",
        "        return torch.ones((B, self.block_size, self.block_size))[:, :num_tokens.max().item(), :num_tokens.max().item()]\n",
        "\n",
        "    def forward(self, idx, targets=None, hidden_cache=None, return_hidden=False):\n",
        "        \"\"\"\n",
        "        :param idx: int Tensor of shape (B,T)\n",
        "        :param hidden_cache: float Tensor of shape (B,P_T,n_embd)\n",
        "        :param targets: int Tensor of shape (B,T_T)\n",
        "        :param return_hidden: bool\n",
        "        (if return_hidden = None)\n",
        "        :returns x: float Tensor of shape (B,T,n_embd)\n",
        "        (else)\n",
        "        :returns logits: float Tensor of shape (B, T, vocab_size)\n",
        "        :returns loss: float Tensor of shape (B) or None\n",
        "        \"\"\"\n",
        "        num_tokens = (idx != -1).type(torch.int).sum(dim=1)\n",
        "        if hidden_cache is not None:\n",
        "          num_tokens = num_tokens + hidden_cache.shape[1]\n",
        "        idx = idx.masked_fill(idx == -1, int(0)).type(torch.int)[:, :num_tokens.max().item()]\n",
        "        if targets is not None:\n",
        "          targets = targets[:, :num_tokens.max().item()]\n",
        "        attention_mask = self.get_attention_mask(num_tokens)\n",
        "        #############################################################################\n",
        "        # TODO:                                                                     #\n",
        "        # Put all the modules of a Transformer together for inference               #\n",
        "        #                                                                           #\n",
        "        # If hidden_cache exists,                                                   #\n",
        "        # then the Transformer inputs should be concatenated in the token dimension #\n",
        "        # First) All Embeddings from Hidden Cache                                   #\n",
        "        # Next)  All Embeddings of tokens from idx.                                 #\n",
        "        #                                                                           #\n",
        "        # All the modules you'll need are listed here:                              #\n",
        "        #                                                                           #\n",
        "        # Note: You can iterate through a nn.ModuleList using a standard for loop.  #\n",
        "        #                                                                           #\n",
        "        # This will take a few lines!                                               #\n",
        "        ##############################################################################\n",
        "        if hidden_cache is not None:\n",
        "            idx_embedding = self.transformer[\"embedding\"](idx)\n",
        "            x = torch.cat([hidden_cache, idx_embedding], dim=1)\n",
        "        else:\n",
        "            x = self.transformer[\"embedding\"](idx)\n",
        "\n",
        "        for block in self.transformer[\"h\"]:\n",
        "            x = block(x, attention_mask)\n",
        "            x = self.transformer[\"ln_f\"](x)\n",
        "\n",
        "        logits = self.lm_head(x)\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        if return_hidden:\n",
        "            return x\n",
        "\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            s_logits = logits\n",
        "            if hidden_cache is not None:\n",
        "              s_logits = logits[:, hidden_cache.shape[1]-1:-1].contiguous()\n",
        "              #print(logits[-1].argmax(dim=1))\n",
        "            loss = F.cross_entropy(\n",
        "                s_logits.reshape(-1, self.vocab_size), targets.reshape(-1), ignore_index=-1\n",
        "            )\n",
        "\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "transformer_def = In[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GvahgUP5G04t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11b55a2-c9e4-456d-ead3-c34756c12816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 0.00M\n",
            "Success 1\n",
            "number of parameters: 0.00M\n",
            "Success 2\n",
            "number of parameters: 0.00M\n",
            "Success 3\n"
          ]
        }
      ],
      "source": [
        "#@title Test Full Transformer Forward Pass\n",
        "\n",
        "def test_transformer():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = GenericTransformer(config)\n",
        "  idx = torch.tensor([[1, 2, 3, 4, 5, -1, -1, -1, -1, -1]], dtype=torch.long)\n",
        "  s = F.softmax(transformer(idx)[0][0, 0], dim=0)\n",
        "  assert torch.allclose(s, torch.tensor([0.1034, 0.0960, 0.1019, 0.1022, 0.1003, 0.1040, 0.0983, 0.1072, 0.0958, 0.0910], dtype=torch.float), atol=1e-5, rtol=1)\n",
        "  print(\"Success 1\")\n",
        "\n",
        "def test_transformer_loss():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = GenericTransformer(config)\n",
        "  idx = torch.tensor([[1, 2, 3, 4, 5, -1, -1, -1, -1, -1]], dtype=torch.long)\n",
        "  target = torch.arange(5).reshape(1, 5)\n",
        "  assert torch.allclose(transformer(idx, targets=target)[1], torch.tensor(2.2973))\n",
        "  print(\"Success 2\")\n",
        "\n",
        "def test_transformer_hidden():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = GenericTransformer(config)\n",
        "  idx = torch.tensor([[1, 2, 3, 4, 5, -1, -1, -1, -1, -1]], dtype=torch.long)\n",
        "  target = torch.arange(5).reshape(1, 5)\n",
        "  hidden = transformer(idx, targets=target, return_hidden=True)\n",
        "  assert torch.allclose(hidden[0, 0], torch.tensor([1.4417, -1.3564,  0.1549, -0.2401]), atol=1e-4)\n",
        "  print(\"Success 3\")\n",
        "\n",
        "test_transformer()\n",
        "test_transformer_loss()\n",
        "test_transformer_hidden()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYNuYWMn0iaS"
      },
      "source": [
        "#### Implement an Encoder Transformer\n",
        "\n",
        "Encoders, like the BERT model you learned about in lecture, utilize bi-directional attention. This means that in the sequence \"A B C\", the representation for token \"B\" will be influenced by tokens A *and* C. When all tokens can attend to all other tokens, the attention_mask is just a matrix of ones.\n",
        "\n",
        "However, since sentences come in a wide range of lengths, we need a way to batch sequences of different lengths together in order to maximize our GPU throughput. The most common way of doing this is called \"Padding\". When you pad an input, you add additional \"pad\" tokens to make it the same length as the longest sequence in a batch. For example, if we wanted to batch \"A B C\" and \"A B C D\" together, we would add a \"pad\" token to \"A B C\". Our resulting batch would be \\[\"A B C \\<pad\\>\", \"A B C D\"\\].\n",
        "\n",
        "Since these pad tokens are meaningless, we want to avoid having them affect our results. To do this, we remove them from the attention mask for that element in the batch. Below, you'll write a function to create such an attention mask for padded sequences given a tensor which contains the number of valid leading tokens for each batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VF8grwOtG-gs"
      },
      "outputs": [],
      "source": [
        "class Encoder(GenericTransformer):\n",
        "    \"\"\"Encoder Style Transformer with Bidirectional Attention\"\"\"\n",
        "    def get_attention_mask(self, num_tokens):\n",
        "        \"\"\"\n",
        "        :param num_tokens: int Tensor of shape (batch size)\n",
        "        :returns attention_mask: int tensor of shape (batch_size, 1, max_tokens, max_tokens)\n",
        "        \"\"\"\n",
        "        B = num_tokens.shape[0]\n",
        "        max_tokens = min(self.block_size, num_tokens.max().item())\n",
        "        ##############################################################################\n",
        "        # TODO:                                                                      #\n",
        "        # Implement a padding mask function.                                         #\n",
        "        # This allows batching sequences of different lengths.                       #\n",
        "        #                                                                            #\n",
        "        # For example, for any row attention_mask[b, i] the following should be true:#\n",
        "        #               For j < num_tokens[b], attention_mask[b, i, j] = 1          #\n",
        "        #               For j >= num_tokens[b],  attention_mask[b, i, j] = 0         #\n",
        "        #                                                                            #\n",
        "        # Reference:https://huggingface.co/docs/transformers/glossary#attention-mask #                                                                #\n",
        "        #                                                                            #\n",
        "        # This should be a 1-3 line function.                                        #\n",
        "        ##############################################################################\n",
        "        attention_mask = torch.ones(B, max_tokens, max_tokens)\n",
        "\n",
        "        for b in range(B):\n",
        "            attention_mask[b, :, num_tokens[b]:] = 0\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return attention_mask.reshape(B, 1, max_tokens, max_tokens)\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "encoder_def = In[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pXGGTqi4G-6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b2c642-6bca-4f13-efa7-08335167e003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 0.00M\n"
          ]
        }
      ],
      "source": [
        "#@title Test Encoder\n",
        "\n",
        "def test_encoder():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = Encoder(config)\n",
        "  mask = transformer.get_attention_mask(torch.tensor([5, 6]))\n",
        "  assert mask[0, :, 0].sum() == 5\n",
        "  assert mask[1, :, 0].sum() == 6\n",
        "\n",
        "\n",
        "test_encoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfA1ktrT2l0a"
      },
      "source": [
        "#### Implement an Decoder Transformer\n",
        "\n",
        "Unlike Encoders, Decoders are a \"causal\" model, meaning that each prediction is only influenced by the tokens which came earlier than it in the input. While \"Encoders\" and \"Decoders\" are often discussed as different types of models, the only core difference is the attention mask used.\n",
        "\n",
        "For decoders, we want the attention mask for each token to only include the previous tokens in the sequence. Despite being functionally very different models, a \"Decoder\" can be implemented with just a one line change of the \"Encoder\" attention mask. You'll implement this below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "je6nfibPHGPr"
      },
      "outputs": [],
      "source": [
        "class Decoder(Encoder):\n",
        "    \"\"\"Decoder Style model with a Causal Attention Mask\"\"\"\n",
        "\n",
        "    def get_attention_mask(self, num_tokens):\n",
        "        \"\"\"\n",
        "        :param num_tokens: int Tensor of shape (batch size)\n",
        "        :returns attention_mask: int tensor of shape (batch_size, 1, block_size, block_size)\n",
        "        \"\"\"\n",
        "        full_attention_mask = super().get_attention_mask(num_tokens)\n",
        "        ##############################################################################\n",
        "        # TODO:                                                                      #\n",
        "        # Modify the output of the full encoder mask to create a \"causal\" mask       #\n",
        "        # such that tokens only attend to tokens which occured earlier in the input. #\n",
        "        #                                                                            #\n",
        "        # For example, for any row attention_mask[b, i} the following should be true:#\n",
        "        #               For j <= i, attention_mask[b, i, j] = 1                      #\n",
        "        #               For j > i,  attention_mask[b, i, j] = 0                      #\n",
        "        #                                                                            #\n",
        "        # This should be a one line function which modifies the full attention_mask  #\n",
        "        ##############################################################################\n",
        "        attention_mask = full_attention_mask.tril()\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return attention_mask\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "decoder_def = In[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "nyg5zzmc_8y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbfb0cd-4e6b-49b5-8e4a-93d9ca831c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 0.00M\n"
          ]
        }
      ],
      "source": [
        "#@title Test Decoder\n",
        "\n",
        "def test_decoder():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = Decoder(config)\n",
        "  mask = transformer.get_attention_mask(torch.tensor([[5], [6]]))\n",
        "  for i in range(5):\n",
        "    assert mask[0, :, i].sum() == i+1\n",
        "  assert mask[0, :, 5].sum() == 5\n",
        "  for i in range(6):\n",
        "    assert mask[1, :, i].sum() == i+1\n",
        "\n",
        "test_decoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UABwUKI93c_A"
      },
      "source": [
        "#### Implement an Decoder Transformer\n",
        "\n",
        "Unlike Encoders, Decoders are a \"causal\" model, meaning that each prediction is only influenced by the tokens which came earlier than it in the input. While \"Encoders\" and \"Decoders\" are often discussed as different types of models, the only core difference is the attention mask used.\n",
        "\n",
        "For decoders, we want the attention mask for each token to only include the previous tokens in the sequence. Despite being functionally very different models, a \"Decoder\" can be implemented with just a one line change of the \"Encoder\" attention mask. You'll implement this below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JEbiacH3JUF8"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, temperature=1.0):\n",
        "    \"\"\"\n",
        "    :param idx: int Tensor of shape (B, T)\n",
        "    :param max_new_tokens: int\n",
        "    :param temperature: Float\n",
        "    :returns idx: int Tensor of shape (B, T+max_new_tokens)\n",
        "    \"\"\"\n",
        "    ##############################################################################\n",
        "    # TODO:                                                                      #\n",
        "    # Sample from your model max_new_tokens times                                #\n",
        "    # You should feed the predictions back into the model each time              #\n",
        "    #                                                                            #\n",
        "    # Adjust the probability distribution to be more or less greedy using        #\n",
        "    # the temperature parameter                                                  #\n",
        "    #                                                                            #\n",
        "    # Reference: https://huggingface.co/blog/how-to-generate#sampling            #\n",
        "    # Temperature Reference:                                                     #\n",
        "    # https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture10-nlg.pdf#page=34 #\n",
        "    ##############################################################################\n",
        "    for i in range(max_new_tokens):\n",
        "        logits = model(idx)[0]\n",
        "        logits = logits/temperature\n",
        "\n",
        "        next_token_probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "        next_tokens = torch.multinomial(next_token_probs, 1).squeeze(-1)\n",
        "        idx = torch.cat([idx, next_tokens.unsqueeze(1)], dim=1)\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "    return idx\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "generate_def = In[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UR1Zn12LanRo",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Test Generation\n",
        "\n",
        "def test_generate():\n",
        "    def dumb_model(idx):\n",
        "      l = torch.zeros(1, 1, 10)\n",
        "      l[0, 0, 0] = 100\n",
        "      l[0, 0, 5] = 90\n",
        "      return l.roll(idx[0, -1].item()+1), None\n",
        "    torch.set_default_device(\"cpu\")\n",
        "    set_seed(3047)\n",
        "    assert torch.allclose(generate(dumb_model, torch.tensor([[0]]), 6), torch.tensor([0,1,2,3,4,5,6]))\n",
        "    temp_gen_1 = generate(dumb_model, torch.tensor([[0]]), 6, temperature=10)\n",
        "    assert torch.allclose(temp_gen_1, torch.tensor([[0, 6, 2, 3, 4, 5, 6]]))\n",
        "\n",
        "test_generate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYnbvnKI3gnF"
      },
      "source": [
        "#### Implement an Encoder Decoder Transformer\n",
        "\n",
        "Now, we'll put together our Encoder and Decoder models. This combination of the two architectures allows us to maximize the signal we can draw from the input using a bi-directional encoder, while generating language using a causal decoder.\n",
        "\n",
        "Below, you'll combine your Encoder and Decoder classes in a forward function making use of the `return_hidden` and `hidden_cache` arguments we supported in our Transformer implementation to pass information between the modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P5L7c5YifKd-"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"Encoder-Decoder Model which combines the two architectures\"\"\"\n",
        "    def __init__(self, encoder_config, decoder_config):\n",
        "        super().__init__()\n",
        "        # Add end of sequence token.\n",
        "        decoder_config.vocab_size += 1\n",
        "        self.vocab_size = decoder_config.vocab_size\n",
        "        self.encoder = Encoder(encoder_config)\n",
        "        self.decoder = Decoder(decoder_config)\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        enc_groups = self.encoder.configure_optimizers(train_config)\n",
        "        dec_groups = self.decoder.configure_optimizers(train_config)\n",
        "        return enc_groups + dec_groups\n",
        "\n",
        "    def forward(self, prefix, targets=None):\n",
        "        \"\"\"\n",
        "        :param prefix: int Tensor of shape (B,P_T)\n",
        "        :param idx: float Tensor of shape (B,P_T,n_embd)\n",
        "        :returns logits: float Tensor of shape (B, vocab_size)\n",
        "        :returns loss: float Tensor of shape (B) or None\n",
        "        \"\"\"\n",
        "        B = prefix.shape[0]\n",
        "        idx = torch.tensor([[]]).repeat(B, 1)\n",
        "        if targets is not None:\n",
        "          idx = torch.cat((idx, targets), dim=1)\n",
        "\n",
        "        ##############################################################################\n",
        "        # TODO:                                                                      #\n",
        "        # Create an Encoder Decoder Model by combining your previous transformers    #\n",
        "        # The Encoder should encode the tokens from prefix into an embeddings        #\n",
        "        # Use these in the hidden_cache to condition decoder generation              #\n",
        "        #                                                                            #\n",
        "        # This should be a 1-2 lines.                                                #\n",
        "        ##############################################################################\n",
        "        encoder_output = self.encoder(prefix, return_hidden=True)\n",
        "        logits, loss = self.decoder(idx, targets=targets, hidden_cache=encoder_output)\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return logits, loss\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "encdec_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwTVJHeG4tVx"
      },
      "source": [
        "This will also require a custom `prefix_generation` function to account for the distinction between a human provided `prefix` and a model generated `idx` in the Encoder Decoder forward pass.\n",
        "\n",
        "Don't worry, this should be only a small change from your original `generate` function above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0X8dl3D64uql"
      },
      "outputs": [],
      "source": [
        "def prefix_generate(model, prefix, max_new_tokens, temperature=1.0):\n",
        "    \"\"\"\n",
        "    :param prefix: int Tensor of shape (B, T)\n",
        "    :param max_new_tokens: int\n",
        "    :param temperature: Float\n",
        "    :returns idx: int Tensor of shape (B, T+max_new_tokens)\n",
        "    \"\"\"\n",
        "    idx = torch.tensor([[]], dtype=torch.long)\n",
        "    ##############################################################################\n",
        "    # TODO:                                                                      #\n",
        "    # Adjust your original generation function to work Encoder-Decoder models    #\n",
        "    #                                                                            #\n",
        "    # Note: This should be a one line change from the original generate function #\n",
        "    ##############################################################################\n",
        "    for i in range(max_new_tokens):\n",
        "        logits = model(prefix, targets=idx)[0]\n",
        "        logits = logits/temperature\n",
        "\n",
        "        next_token_probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "        next_tokens = torch.multinomial(next_token_probs, 1).squeeze(-1)\n",
        "        idx = torch.cat([idx, next_tokens.unsqueeze(1)], dim=1)\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "    return idx\n",
        "\n",
        "#Do not change, it will break the AutoGrader\n",
        "pref_generate_def = In[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "id": "kICaKJURf9-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec5ceb2-5a17-4efa-b15b-1bb7ccd0e352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 0.09M\n",
            "number of parameters: 0.09M\n",
            "running on device cpu\n",
            "iter_dt 0.00ms; iter 0: train loss 1.44797\n",
            "iter_dt 98.09ms; iter 100: train loss 0.12163\n",
            "iter_dt 65.27ms; iter 200: train loss 0.02322\n",
            "iter_dt 60.46ms; iter 300: train loss 0.00459\n",
            "iter_dt 61.29ms; iter 400: train loss 0.05802\n"
          ]
        }
      ],
      "source": [
        "#@title End to End Test of Encoder Decoder Training\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from gtgpt.trainer import Trainer\n",
        "\n",
        "import pickle\n",
        "\n",
        "class SortDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for the Sort problem. E.g. for problem length 6:\n",
        "    Input: 0 0 2 1 0 1 -> Output: 0 0 0 1 1 2\n",
        "    Which will feed into the transformer concatenated as:\n",
        "    input:  0 0 2 1 0 1 0 0 0 1 1\n",
        "    output: I I I I I 0 0 0 1 1 2\n",
        "    where I is \"ignore\", as the transformer is reading the input sequence\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, split, length=6, num_digits=3):\n",
        "        assert split in {'train', 'test'}\n",
        "        self.split = split\n",
        "        self.length = length\n",
        "        self.num_digits = num_digits\n",
        "\n",
        "    def __len__(self):\n",
        "        return 10000 # ...\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.num_digits\n",
        "\n",
        "    def get_block_size(self):\n",
        "        # the length of the sequence that will feed into transformer,\n",
        "        # containing concatenated input and the output, but -1 because\n",
        "        # the transformer starts making predictions at the last input element\n",
        "        return 20\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # use rejection sampling to generate an input example from the desired split\n",
        "        while True:\n",
        "            # generate some random integers\n",
        "            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n",
        "            # half of the time let's try to boost the number of examples that\n",
        "            # have a large number of repeats, as this is what the model seems to struggle\n",
        "            # with later in training, and they are kind of rate\n",
        "            if torch.rand(1).item() < 0.5:\n",
        "                if inp.unique().nelement() > self.length // 2:\n",
        "                    # too many unqiue digits, re-sample\n",
        "                    continue\n",
        "            # figure out if this generated example is train or test based on its hash\n",
        "            h = hash(pickle.dumps(inp.tolist()))\n",
        "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
        "            if inp_split == self.split:\n",
        "                break # ok\n",
        "\n",
        "        # solve the task: i.e. sort\n",
        "        sol = torch.sort(inp)[0]\n",
        "\n",
        "        # concatenate the problem specification and the solution\n",
        "        cat = torch.cat((inp, sol), dim=0)\n",
        "\n",
        "        # the inputs to the transformer will be the offset sequence\n",
        "        x = cat[:self.length].clone()\n",
        "        y = cat[self.length:].clone()\n",
        "        # we only want to predict at output locations, mask out the loss at the input locations\n",
        "        return x, y\n",
        "\n",
        "def test_encoder_decoder():\n",
        "  # print an example instance of the dataset\n",
        "  train_dataset = SortDataset('train')\n",
        "  test_dataset = SortDataset('test')\n",
        "  x, y = train_dataset[0]\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = train_dataset.get_vocab_size()\n",
        "  config.block_size = train_dataset.get_block_size()\n",
        "  config.n_layer = 3\n",
        "  config.n_embd = 48\n",
        "  config.n_head = 3\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  model = EncoderDecoder(config, config)\n",
        "  train_config = Trainer.get_default_config()\n",
        "  train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
        "  train_config.max_iters = 500\n",
        "  train_config.num_workers = 0\n",
        "  train_config.device = \"cpu\"\n",
        "  trainer = Trainer(train_config, model, train_dataset)\n",
        "  def batch_end_callback(trainer):\n",
        "      if trainer.iter_num % 100 == 0:\n",
        "          print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
        "  trainer.set_callback('on_batch_end', batch_end_callback)\n",
        "\n",
        "  trainer.run()\n",
        "  model.eval()\n",
        "  assert torch.allclose(prefix_generate(model, torch.tensor([[2, 1, 1, 0, 1, 2]]), max_new_tokens=6), torch.tensor([[0, 1, 1, 1, 2, 2]]))\n",
        "\n",
        "test_encoder_decoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3xuBrm4449O"
      },
      "source": [
        "# You've implemented a language model!\n",
        "\n",
        "## Now let's put it to use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "W9XRRfet5CIL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "ab380e0bb858470ab503ff3ddad94957",
            "fe1d76599ee743bca398a2e4c563dee9",
            "15d9aa0aa3294897bdc1a73dfdf2f234",
            "540aacf467be45e8ad1713b7db69fc93",
            "4c74f1a40af04eaeadde16a121c13e14",
            "980f3312915f433093e77c181d29d736",
            "6e0f01619ea747b083a6eba1001731a5",
            "70b586584b6946d1a5190cee85a6b077",
            "da6e8cff11f14edd9c2caf2bdaad0f51",
            "0d0a0430a26945f29fa30527c8817de1",
            "252d065da2594208ae72e1f79afb1e3d",
            "6b9641ffbeea4fd9b7e7b44bbf418f2a",
            "1a2fa93c3530497dac2f136b05ac5025",
            "a5923a85182b4f2ba8c256307cef79e6",
            "ad2f0c03784549ddafdbf3ec26d7bf8f",
            "05eb98bbe28a4432ab286308e3cadb68",
            "356d3085066d441a900c18973e58d939",
            "fdb9241c3b2b4b00a1988feb09e718d3",
            "3d8bf9e3d8854b52886acbb4a86a6b09",
            "5bb117850b6a4cdf8b7f7c40b1d0dcc4",
            "4c4ce8aea0ad43d5a58773cb862c2157",
            "806347dfe0654ee68a289d7c5303bfdc",
            "41252545fcc042719cceedf84bdf649a",
            "9aca05041600432580827c47f9f17969",
            "bd53e273f33f4336b4259c9d9246024c",
            "bb8ebd6f738143b1b75f6ba299419b51",
            "aa822136eafd4d4c89741957264cfd2d",
            "0a5c1a9ab71e424d8bae0a2783fdd1d8",
            "7b8c70643dd74705a4be550247b32b36",
            "1ff577ad4ef24420b3ea6b604bcba853",
            "e6c7382c800d430d8cfc3b6f4dafe15c",
            "a59e135b41fd4a16b8a8c0be6a1e1c8b",
            "c864227f8dae4c949c2d312a5a493206",
            "2333a6d74a5d4140a82550c034ad3149",
            "e4f15e353e2f46c6bfed7f203b85375b",
            "3b7b53a50443455ba26cab604b4c6397",
            "0208fd531c2a4ad69f21d07647c330c2",
            "46e0f469deac43c7a109038680505104",
            "a7f813057c05486f996cfbd1fdebcabc",
            "b057ec34f47446e3a79cd0b301c71dbc",
            "c08d9724286d411cabe0a59b128490b6",
            "92260cf94d7b4952bbe154a9fe1995b8",
            "fd37b32c461b45c3b84e184b14f77949",
            "a897c3ef92824843b247bbabf79c2721",
            "6fabe9b4e2884cd2ba046f48e8cfc19b",
            "67b9eb35dfdf44af9b2097b4ad3da2a8",
            "fa8d658f3d22496b89ae083569fbd2a8",
            "26772ae140e94adfa3ffa673fb4dd808",
            "57eb8f849ae54f70a60291710ca77a53",
            "b85b7f592f3c4af59db37c4168fb2eea",
            "67b3f743f0d84eae8f7bee6112787fb0",
            "74f01fe58e224b4fb3915fff7381fc7b",
            "2161b200ed044cd0bec9fce48dc8e8ec",
            "8c9436483acf4b31bdb144b1b28f597c",
            "179c09ff627e4402a21cae067f15ca08",
            "99cc2a7b3dd24407a9ca633602e9fac4",
            "a66ede6d201c423e9105aa18e305875f",
            "93e7e836e6c54c58ae235f6f0e62bfa0",
            "9140f6fa03df42fa802130637aa412ee",
            "67142d2f66394d14894fecd0d64d7b7c",
            "18dde0b58732418fb1bf9f959ed77323",
            "22863eb832774b89bfa1fe467228751b",
            "d42d487d7ce242f786790dbca1044b05",
            "95cbbb22f8d948d394fde80a03271e58",
            "50b41a93939a4bd0a8f63365bc21253c",
            "bbfb6384cb0f427f87e82fcbfd97c4c3",
            "7d21ffd70ef44eb6a8ea6434bebcfeda",
            "d3cd4e87bf964c41bf9b2f470b21384f",
            "ab2e7453b49e4c30ba7ed85b71ec9a4d",
            "93d89c158d06428ca321c6a7e557dbd0",
            "818253ed0ef940b49b74fd9ed27fc6d2",
            "fbfb129277c744249aaed8fe88b660bc",
            "345f637515154597949949b26251a6a7",
            "f98bfd4de3104f52a82b47ae821ec7c3",
            "7ba149b45ede4a8fb89abeca5f41f362",
            "5e72b078abdd4da09a496cdb47f33742",
            "d70431167bf14a5aa359ed517ef53364",
            "e0c7c062a75c4e71b0beb07056454594",
            "bb0adb06cf544f048f5a9ceaf2e80bc9",
            "42364ee2e1c04ff6954ec3abda569cce",
            "a019c62bd2124dd6abf655e793746f60",
            "44982efe57694741bd582ce55705468a",
            "23b2d185a9f441e081166e8d79ad29ba",
            "529cac0d5b72494083262d5cc77ecf26",
            "abfeb4cbc8c4487b8b8a8d58b1bc3d35",
            "c2cce30979594e6b865f957b71e1723f",
            "2c6dd04277a745849cf1d4083cc70f87",
            "86f4c0ad8cdb48dfbd710889022d3d7b",
            "948f73c94f974114ade716e1b760a5c1",
            "8984039dc38d4850bdf6a0faf1188985",
            "decdd945c06442a9a7ff75093bc594dc",
            "f7d9c9ce51ad4bec8a6f071f06042acd",
            "532698df74c74b86bb5d938984d786c9",
            "3da10b04bf4a479d9446ee618c976d3a",
            "ea7f1151224d4b7a841f104417d24f44",
            "a086048db4c84528853dfe270f99d02a",
            "e8d430f7dd98412c868f756c0bf71a20",
            "cd9ae31cffc9474b88b2c4e5743bd0f1",
            "b6bdfc673750491799ad6ec7c3cc0cab"
          ]
        },
        "outputId": "41093f23-f88e-4f00-e614-06902a29bc12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab380e0bb858470ab503ff3ddad94957"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b9641ffbeea4fd9b7e7b44bbf418f2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41252545fcc042719cceedf84bdf649a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.50M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2333a6d74a5d4140a82550c034ad3149"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/188k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fabe9b4e2884cd2ba046f48e8cfc19b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99cc2a7b3dd24407a9ca633602e9fac4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d21ffd70ef44eb6a8ea6434bebcfeda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0c7c062a75c4e71b0beb07056454594"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/13232 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "948f73c94f974114ade716e1b760a5c1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Language Modeling Setup (Do Not Change)\n",
        "from gtgpt.trainer import Trainer\n",
        "from tqdm import tqdm\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.pre_tokenizers import ByteLevel\n",
        "from tokenizers.trainers import UnigramTrainer, BpeTrainer\n",
        "from tokenizers.models import Unigram, BPE\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "class LMDataset(Dataset):\n",
        "    def __init__(self, split, data, tokenizer, model):\n",
        "        assert split in {'train', 'test'}\n",
        "        self.model_type = \"EncDec\" if issubclass(type(model), EncoderDecoder) else \"Dec\"\n",
        "        if split == \"train\":\n",
        "          self.start_split = 0\n",
        "          self.end_split = 30000\n",
        "        else:\n",
        "          self.start_split = 30000\n",
        "          self.end_split = 40000\n",
        "        self.split = split\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.block_size = max([len(self.tokenizer.encode(inp)) for inp in self.data])\n",
        "        self.process()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[self.start_split:self.end_split])\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.tokenizer.get_vocab_size()\n",
        "\n",
        "    def get_block_size(self):\n",
        "        # the length of the sequence that will feed into transformer,\n",
        "        # containing concatenated input and the output, but -1 because\n",
        "        # the transformer starts making predictions at the last input element\n",
        "        return self.block_size\n",
        "\n",
        "    def process(self):\n",
        "      new_data = []\n",
        "      for inp in tqdm(self.data):\n",
        "        if self.model_type == \"EncDec\":\n",
        "          x_inp = inp.split(\"[SEP]\")[0] + \"[SEP]\"\n",
        "          y_inp = inp.split(\"[SEP]\")[1]\n",
        "          x = self.tokenizer.encode(x_inp)\n",
        "          y = self.tokenizer.encode(y_inp)\n",
        "        else:\n",
        "          x = self.tokenizer.encode(inp)\n",
        "          y = x[1:]\n",
        "          x = x[:-1]\n",
        "        x = x + ([-1] * (self.get_block_size() - len(x)))\n",
        "        y = y + ([-1] * (self.get_block_size() - len(y)))\n",
        "        new_data.append((x, y))\n",
        "      self.data = new_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      x, y = self.data[self.start_split + idx]\n",
        "      return torch.tensor(x), torch.tensor(y)\n",
        "\n",
        "def format_review(row):\n",
        "  return {\"text\": f\"{row['translation']['eng']}[SEP]{row['translation']['engyay']}[END]\"}\n",
        "\n",
        "dataset = load_dataset(\"cdleong/piglatin-mt\")[\"train\"]\n",
        "data = [row[\"text\"] for row in dataset.map(format_review).to_list()]\n",
        "set_seed(3047)\n",
        "random.shuffle(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcvP7ZXLEoq0"
      },
      "source": [
        "#### Training a Language Model from Scratch\n",
        "\n",
        "Above, we set up code which loads WikiHow articles as a training dataset either for pure Decoder models or with the Title passed as a prefix for an EncoderDecoder model. We want to train a model to translate between English and Pig-Latin!\n",
        "\n",
        "Below is an implementation which achieves between 40 and 50 percent accuracy. Modify the tokenizer, architecture, or hyperparameters to  decrease the loss as much as possible and drive accuracy above 80%. Report what you changed and your intuitions for why you changed it in the report powerpoint file and upload it as a PDF to GradeScope.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SBbSkVLq5Eir"
      },
      "outputs": [],
      "source": [
        "# Incredibly Simplified Tokenizer so that you can manually hack it!\n",
        "# Feel free to add special tokens or modify as you wish.\n",
        "# For real world tokenizer usage, see https://huggingface.co/docs/tokenizers/\n",
        "class Tokenizer():\n",
        "  def __init__(self):\n",
        "    self.DELIM = \"|[DELIM]|\"\n",
        "    self.special_tokens = [\"[SEP]\", \"[END]\"]\n",
        "    self.special_tokens = [self.stringify(list(bytes(tok, \"utf-8\"))) for tok in self.special_tokens]\n",
        "    self.vocab_size = 256 + len(self.special_tokens)\n",
        "\n",
        "  def stringify(self, b_enc):\n",
        "    s_enc = [str(b) for b in b_enc]\n",
        "    return self.DELIM.join(s_enc)\n",
        "\n",
        "  def get_vocab_size(self):\n",
        "    return self.vocab_size\n",
        "\n",
        "  def encode(self, inp):\n",
        "    s_enc = self.stringify(list(bytes(inp, \"utf-8\")))\n",
        "    for i, tok in enumerate(self.special_tokens):\n",
        "      s_enc = s_enc.replace(tok, str(255+i+1))\n",
        "    return [int(s) for s in s_enc.split(self.DELIM)]\n",
        "\n",
        "  def decode(self, inp):\n",
        "    s_enc = self.stringify(inp)\n",
        "    for i, tok in enumerate(self.special_tokens):\n",
        "      s_enc = s_enc.replace(str(255+i+1), tok)\n",
        "    return  bytes([int(c) for c in s_enc.split(self.DELIM)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5cfrrAkfDIQT"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.set_default_device(DEVICE)\n",
        "def train(data, model_type=\"Decoder\",\n",
        "          learning_rate = 5e-4,\n",
        "          batch_size = 16,\n",
        "          max_iters = 10000,\n",
        "          dec_n_layer=1,\n",
        "          dec_n_embd=52,\n",
        "          dec_n_head = 1,\n",
        "          enc_n_layer=None,\n",
        "          enc_n_embd=None,\n",
        "          enc_n_head=None):\n",
        "  # Model Setup\n",
        "  tokenizer = Tokenizer()\n",
        "  dec_config = DummyTransformer.get_default_config()\n",
        "  dec_config.vocab_size = tokenizer.get_vocab_size()\n",
        "  dec_config.block_size = max([len(tokenizer.encode(inp)) for inp in data])\n",
        "  dec_config.n_layer = dec_n_layer\n",
        "  dec_config.n_embd = dec_n_embd\n",
        "  dec_config.n_head = dec_n_head\n",
        "  if model_type == \"Decoder\":\n",
        "    model = Decoder(dec_config)\n",
        "  else:\n",
        "    enc_config = DummyTransformer.get_default_config()\n",
        "    enc_config.vocab_size = tokenizer.get_vocab_size()\n",
        "    enc_config.block_size = max([len(tokenizer.encode(inp)) for inp in data])\n",
        "    enc_config.n_layer = enc_n_layer\n",
        "    enc_config.n_embd = enc_n_embd\n",
        "    enc_config.n_head = enc_n_head\n",
        "    model = EncoderDecoder(enc_config, dec_config)\n",
        "\n",
        "  # Training Config\n",
        "  train_config = Trainer.get_default_config()\n",
        "  train_config.learning_rate = learning_rate\n",
        "  train_config.max_iters = max_iters\n",
        "  train_config.batch_size = batch_size\n",
        "  train_config.num_workers = 0\n",
        "  train_config.device = DEVICE\n",
        "  train_ds = LMDataset(\"train\", data, tokenizer, model)\n",
        "  # Training Loop\n",
        "  trainer = Trainer(train_config, model, train_ds)\n",
        "  def batch_end_callback(trainer):\n",
        "      if trainer.iter_num % 100 == 0:\n",
        "          tqdm.write(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
        "          prefix = torch.tensor([tokenizer.encode(\"translate this to piglatin[SEP]\")])\n",
        "          if model_type == \"Decoder\":\n",
        "            output = generate(model, prefix, 100, 0.1)\n",
        "          else:\n",
        "            output = prefix_generate(model, prefix, 100, 0.1)\n",
        "          print(tokenizer.decode(output.cpu().numpy()[0]).split(bytes(\"[END]\", \"utf-8\"))[0])\n",
        "  trainer.set_callback('on_batch_end', batch_end_callback)\n",
        "  trainer.run()\n",
        "  return model, trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "B7WzG16__KFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164753c7-1c1f-467c-9e5e-ea03074fff8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 0.23M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13232/13232 [00:01<00:00, 10190.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on device cuda:0\n",
            "iter_dt 0.00ms; iter 0: train loss 5.56554\n",
            "b'translate this to piglatin[SEP]\\xea)\\xe4!\\x1b\" \\xbaM]\\'\\xd6\\tn4K\\xc7t\\x17\\xb0\\xa1Lo\\xff\\n\\xd4\\xb3\\x17\\xa2\\t\\x0bq\\xea\\xdf\\np\\xfe\\x8b\\xdf\\x19\\xb4V\\xe4\\xbc\\x83n\\x19+e\\x84\\r\\xba(\\xab\\xfd\\xbeA\\xd2\\x8d\\x86\\xd5\\x98\\x9a8\\xe7\\xd0\\x98\\xbe~\\xab\\x16\\xdc\\xa1\\xbe\\xf7\\xb6\\xe6\\xd6\\x9b\\x92\\xec^\\x0cn*7\\xd0G\\xc0\\x8172\\xc8*Y\\xfc\\xcb\\xabX7'\n",
            "iter_dt 180.34ms; iter 100: train loss 2.13212\n",
            "b'translate this to piglatin[SEP]e the the the the the the the the the there[SEP]e-ay e-ay e-ay e-ay ay e-ay ay on-ay e-ay e-ay e-ay oray'\n",
            "iter_dt 184.50ms; iter 200: train loss 1.93205\n",
            "b'translate this to piglatin[SEP]an-thay anthand-thay ay ond-thay ay and-thay ond-thay and-ay on-thay e-ay ay-t-thay ay-thay ay of-t-'\n",
            "iter_dt 184.01ms; iter 300: train loss 1.79558\n",
            "b'translate this to piglatin[SEP]an-ay on-thay ond-thay orend the the the[SEP]an-thay o-ay e-thay e-thay of-ay out-thay o-thay e-thay o-t'\n",
            "iter_dt 187.64ms; iter 400: train loss 1.70899\n",
            "b'translate this to piglatin[SEP]an-ay out-t ey e-thay out of the the the the[SEP]at-thay e-thay o-tay e-thay o-thay an-tay o-tay e-thay '\n",
            "iter_dt 214.34ms; iter 500: train loss 1.63320\n",
            "b'translate this to piglatin[SEP]ass-tay eand-ay e-thay and-ay and-ay e-thay out-bay e-thay o-tay e-thay o-tay e-thay oun-ay e-thay e'\n",
            "iter_dt 182.06ms; iter 600: train loss 1.53202\n",
            "b'translate this to piglatin[SEP]ansans-thay is-thay is-thay is-ay is-thay is-thay is-thay is-thay ouldis-ay is-ay is-thay is-thay in'\n",
            "iter_dt 186.09ms; iter 700: train loss 1.32601\n",
            "b'translate this to piglatin[SEP]and-ay ancantate-pay of-ay of-ay of-ay ith-thay is-thay it-thay icatinant-pay iglatinatin-cay of-ay '\n",
            "iter_dt 188.38ms; iter 800: train loss 1.17379\n",
            "b'translate this to piglatin[SEP]anlslanans-ay-thay. o-t-ay ight-pay o-tay a-ay is-thay oiglatin-cay o-tay igllatinantin-pay iglatini'\n",
            "iter_dt 185.36ms; iter 900: train loss 1.03987\n",
            "b'translate this to piglatin[SEP]anslans-thay o-thay igllans-pay iglage-pay in[SEP]anslae-thay o-pay iglatintain-cay iglatintinatintin-ay'\n",
            "iter_dt 185.66ms; iter 1000: train loss 0.99355\n",
            "b'translate this to piglatin[SEP]anday-thay is-tay-tay in-ay islla-ay o-tay in[SEP]anatins-thay iglatintiinatinantin-ay o-tiinaty-pay isl'\n",
            "iter_dt 184.96ms; iter 1100: train loss 0.94684\n",
            "b'translate this to piglatin[SEP]anste-thay inte-tay.'\n",
            "iter_dt 185.67ms; iter 1200: train loss 0.88960\n",
            "b'translate this to piglatin[SEP]ans-tray at-thay is-tay o-tay iglating-tay. attinating-pay o-tay iglatintinn-ay'\n",
            "iter_dt 153.70ms; iter 1300: train loss 0.85688\n",
            "b'translate this to piglatin[SEP]anste-thay is-thay o-tay igratintion-pay ortion-pay iglatintintintinti-pay'\n",
            "iter_dt 188.43ms; iter 1400: train loss 0.85016\n",
            "b'translate this to piglatin[SEP]anslate-tray at-thay is-thay iglatin-pay ittio-thay iglatintinatin-pay iglatin-pay, intin-pay'\n",
            "iter_dt 187.17ms; iter 1500: train loss 0.83696\n",
            "b'translate this to piglatin[SEP]anslans-thray is-thay o-thay igratin-pay in-ay iglanins-pay iglatinns-pay igh-pay'\n",
            "iter_dt 194.01ms; iter 1600: train loss 0.80458\n",
            "b'translate this to piglatin[SEP]ay ans-thay isth-thay orsclatintinat-thay in-thay intin-pay o-play iglatin-pay'\n",
            "iter_dt 186.51ms; iter 1700: train loss 0.79353\n",
            "b'translate this to piglatin[SEP]anslat-thay is-thay is-tay iglatinting-pay ist-pay islatintin-pay, inglantin-pay ig-bay is-ay'\n",
            "iter_dt 214.11ms; iter 1800: train loss 0.76623\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay itther-play inslatinng-pay'\n",
            "iter_dt 183.20ms; iter 1900: train loss 0.75912\n",
            "b'translate this to piglatin[SEP]ayanslate-tray is-tay o-tay islatintin-pay'\n",
            "iter_dt 189.08ms; iter 2000: train loss 0.74561\n",
            "b'translate this to piglatin[SEP]ans-tray islay-thay o-thay isplatintinslatin--pray o-tay iglaninan-pay'\n",
            "iter_dt 223.86ms; iter 2100: train loss 0.71789\n",
            "b'translate this to piglatin[SEP]anslay-tray ithis-thay o-tay o-thay iglatinnt-pray islatinnin-pay'\n",
            "iter_dt 184.47ms; iter 2200: train loss 0.70308\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tray is-tay iglating-pay iblatinated-pay'\n",
            "iter_dt 182.36ms; iter 2300: train loss 0.70864\n",
            "b'translate this to piglatin[SEP]ayrate-thay is-thay ins-thay inglatinatin-tay'\n",
            "iter_dt 182.69ms; iter 2400: train loss 0.68469\n",
            "b'translate this to piglatin[SEP]atrate-thray is-thay o-tatinay'\n",
            "iter_dt 183.90ms; iter 2500: train loss 0.66148\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglay iglatine-pay atinnate-pay'\n",
            "iter_dt 156.54ms; iter 2600: train loss 0.66504\n",
            "b'translate this to piglatin[SEP]anslate-tray is-t-thay o-tay iglatinnatiningl-pay'\n",
            "iter_dt 188.70ms; iter 2700: train loss 0.65032\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-t-pay iglatinatiglatin-pay'\n",
            "iter_dt 193.07ms; iter 2800: train loss 0.65059\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-thay iglatinning-pay iglatin-ay'\n",
            "iter_dt 188.66ms; iter 2900: train loss 0.63048\n",
            "b'translate this to piglatin[SEP]ans ans-tray is-thay o-thay iglatintinglat-pay'\n",
            "iter_dt 184.88ms; iter 3000: train loss 0.63936\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay is-tay o-prpay iglatint-pay'\n",
            "iter_dt 182.95ms; iter 3100: train loss 0.63044\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay is-tay o-tay iglatintilatinslatine-pay'\n",
            "iter_dt 188.16ms; iter 3200: train loss 0.63917\n",
            "b'translate this to piglatin[SEP]anclate-tray is-thay is-tay iglatinatiglatinglatin-pay'\n",
            "iter_dt 188.03ms; iter 3300: train loss 0.63883\n",
            "b'translate this to piglatin[SEP]anslate-tray o-tay is-tatay o-pay iglatin-payatin-tay'\n",
            "iter_dt 216.69ms; iter 3400: train loss 0.62568\n",
            "b'translate this to piglatin[SEP]aynslate-tray o-thay is-thay o-tay iglatinnoint-pray'\n",
            "iter_dt 181.05ms; iter 3500: train loss 0.61198\n",
            "b'translate this to piglatin[SEP]anslay islate-thay is-tay o-play igelatin-pay'\n",
            "iter_dt 185.34ms; iter 3600: train loss 0.61591\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tay o-tay iglatinatininglatin-pay'\n",
            "iter_dt 182.34ms; iter 3700: train loss 0.59856\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatintininglating-pay'\n",
            "iter_dt 181.97ms; iter 3800: train loss 0.59177\n",
            "b'translate this to piglatin[SEP]anslans-tray is-thay o-tay a-ay iglatinnnatino-payy'\n",
            "iter_dt 127.70ms; iter 3900: train loss 0.59128\n",
            "b'translate this to piglatin[SEP]anslans-thay is-thay o-tay iglatin-ay'\n",
            "iter_dt 182.17ms; iter 4000: train loss 0.58931\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tray o-tay iglatintinglatinin-pay'\n",
            "iter_dt 184.06ms; iter 4100: train loss 0.58906\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay is-pay iglating-pay'\n",
            "iter_dt 212.62ms; iter 4200: train loss 0.58403\n",
            "b'translate this to piglatin[SEP]anslay islate-tray o-tay intiglay iiglatin-pay'\n",
            "iter_dt 189.37ms; iter 4300: train loss 0.58119\n",
            "b'translate this to piglatin[SEP]anslanslate-tray o-thay o-tay iglatinl-pay'\n",
            "iter_dt 181.46ms; iter 4400: train loss 0.57964\n",
            "b'translate this to piglatin[SEP]ansate-tray is-thay o-tay iglay-pay iglatin-pay'\n",
            "iter_dt 184.11ms; iter 4500: train loss 0.58237\n",
            "b'translate this to piglatin[SEP]anslate-tray is-t-thay o-tay o-bay iglatin-pay'\n",
            "iter_dt 185.66ms; iter 4600: train loss 0.58231\n",
            "b'translate this to piglatin[SEP]ante-tray islate-thay o-tay iglatinglatin-pay'\n",
            "iter_dt 219.09ms; iter 4700: train loss 0.58203\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-thay iglatininn-pay'\n",
            "iter_dt 186.04ms; iter 4800: train loss 0.56346\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatinntinatin-pay'\n",
            "iter_dt 188.84ms; iter 4900: train loss 0.57247\n",
            "b'translate this to piglatin[SEP]ansans-tray is-thay o-tay omigelatinn-pay'\n",
            "iter_dt 184.62ms; iter 5000: train loss 0.56662\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay of-tay iglatin-pay'\n",
            "iter_dt 182.89ms; iter 5100: train loss 0.55458\n",
            "b'translate this to piglatin[SEP]anslate-tray o-thay is-tay iglatinn-pay'\n",
            "iter_dt 152.98ms; iter 5200: train loss 0.55600\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay'\n",
            "iter_dt 181.75ms; iter 5300: train loss 0.55973\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tay o-tay iglatin-pay'\n",
            "iter_dt 183.75ms; iter 5400: train loss 0.55418\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tay o-tay iglatin-pay'\n",
            "iter_dt 188.63ms; iter 5500: train loss 0.56368\n",
            "b'translate this to piglatin[SEP]anslay-te-tray is-tay o-tay iglatin-pay'\n",
            "iter_dt 184.98ms; iter 5600: train loss 0.56138\n",
            "b'translate this to piglatin[SEP]anslate-thrate-thay is-tay o-tay iglating-pay'\n",
            "iter_dt 180.98ms; iter 5700: train loss 0.55877\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay o-tiglatin-pay'\n",
            "iter_dt 181.07ms; iter 5800: train loss 0.56100\n",
            "b'translate this to piglatin[SEP]ansate-tay is-thay o-thay iglatin-pay'\n",
            "iter_dt 186.87ms; iter 5900: train loss 0.55884\n",
            "b'translate this to piglatin[SEP]ansalate-tray is-thay o-tay iglatiny-pay'\n",
            "iter_dt 193.41ms; iter 6000: train loss 0.55636\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-thay'\n",
            "iter_dt 186.82ms; iter 6100: train loss 0.54486\n",
            "b'translate this to piglatin[SEP]anslate-tray o-thay o-tay iglatinn-pay'\n",
            "iter_dt 180.60ms; iter 6200: train loss 0.56076\n",
            "b'translate this to piglatin[SEP]ansla-tray is-thay o-tay iglatine-pay'\n",
            "iter_dt 181.45ms; iter 6300: train loss 0.56240\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 181.07ms; iter 6400: train loss 0.53721\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-thay o-tay'\n",
            "iter_dt 150.02ms; iter 6500: train loss 0.53886\n",
            "b'translate this to piglatin[SEP]aslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 185.46ms; iter 6600: train loss 0.54279\n",
            "b'translate this to piglatin[SEP]anslate-tray os-thay o-thay is-pay'\n",
            "iter_dt 183.27ms; iter 6700: train loss 0.53997\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tay o-tay iglatin-pay'\n",
            "iter_dt 182.81ms; iter 6800: train loss 0.53726\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatinn-pay'\n",
            "iter_dt 184.75ms; iter 6900: train loss 0.54292\n",
            "b'translate this to piglatin[SEP]ateate-tay is-thay o-tay o-tay iglatin-pay'\n",
            "iter_dt 211.12ms; iter 7000: train loss 0.54780\n",
            "b'translate this to piglatin[SEP]anslans-tray is-tay of-tay iglatin-pay'\n",
            "iter_dt 185.52ms; iter 7100: train loss 0.54584\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay ilatin-pay'\n",
            "iter_dt 188.39ms; iter 7200: train loss 0.54282\n",
            "b'translate this to piglatin[SEP]anste-tray is-thay o-tay iglatiglatin-pay'\n",
            "iter_dt 188.75ms; iter 7300: train loss 0.54267\n",
            "b'translate this to piglatin[SEP]anslate-thay islay o-tay iglatin-pay'\n",
            "iter_dt 183.02ms; iter 7400: train loss 0.53087\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 181.67ms; iter 7500: train loss 0.53972\n",
            "b'translate this to piglatin[SEP]anslate-tray o-tay is-tay iglatin-pay'\n",
            "iter_dt 181.97ms; iter 7600: train loss 0.53406\n",
            "b'translate this to piglatin[SEP]anslate-tray ohis-thay iglatin-patin-pay'\n",
            "iter_dt 184.74ms; iter 7700: train loss 0.52410\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tray o-tay igla-pay iglatin-pay'\n",
            "iter_dt 132.22ms; iter 7800: train loss 0.52457\n",
            "b'translate this to piglatin[SEP]anslate-tray o-thay ato-tay icglatin-pay'\n",
            "iter_dt 184.15ms; iter 7900: train loss 0.53062\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 217.81ms; iter 8000: train loss 0.52799\n",
            "b'translate this to piglatin[SEP]ananslate-tray is-tay o-tay iglan-pay'\n",
            "iter_dt 187.30ms; iter 8100: train loss 0.52908\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatinn-pay'\n",
            "iter_dt 186.04ms; iter 8200: train loss 0.54271\n",
            "b'translate this to piglatin[SEP]anslate-trate-thay is-thay o-pay igglatin-pay'\n",
            "iter_dt 184.10ms; iter 8300: train loss 0.53238\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 180.44ms; iter 8400: train loss 0.53453\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 214.75ms; iter 8500: train loss 0.53285\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 187.66ms; iter 8600: train loss 0.52965\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 182.54ms; iter 8700: train loss 0.51893\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay isglatin-pay'\n",
            "iter_dt 181.80ms; iter 8800: train loss 0.52658\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 180.89ms; iter 8900: train loss 0.52173\n",
            "b'translate this to piglatin[SEP]anslate-tray o-thay o-tay iglatin-pay'\n",
            "iter_dt 214.39ms; iter 9000: train loss 0.52317\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-thay iglatin-pay'\n",
            "iter_dt 127.50ms; iter 9100: train loss 0.51436\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay oo-tay iglatic-pay'\n",
            "iter_dt 213.23ms; iter 9200: train loss 0.52194\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglat-pay iglatin-pay'\n",
            "iter_dt 211.15ms; iter 9300: train loss 0.52358\n",
            "b'translate this to piglatin[SEP]anslatrate-tray o-tay o-tay iglatin-pay'\n",
            "iter_dt 183.80ms; iter 9400: train loss 0.51659\n",
            "b'translate this to piglatin[SEP]anslate-tray is-tay o-tay iglatin-pay'\n",
            "iter_dt 186.73ms; iter 9500: train loss 0.51923\n",
            "b'translate this to piglatin[SEP]anslateslate-thay is-tay o-tay iglatin-pay'\n",
            "iter_dt 182.07ms; iter 9600: train loss 0.52426\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 180.49ms; iter 9700: train loss 0.52969\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay iglatin-pay'\n",
            "iter_dt 217.60ms; iter 9800: train loss 0.52563\n",
            "b'translate this to piglatin[SEP]anslam-thray is-thay o-tay iglatin-pay'\n",
            "iter_dt 189.87ms; iter 9900: train loss 0.53370\n",
            "b'translate this to piglatin[SEP]anslate-tray is-thay o-tay o-tay iglatin-pay'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decoder(\n",
              "  (transformer): ModuleDict(\n",
              "    (embedding): Embedding(\n",
              "      (vocab_embeddings): Embedding(258, 64)\n",
              "      (position_embeddings): Embedding(200, 64)\n",
              "    )\n",
              "    (h): ModuleList(\n",
              "      (0-3): 4 x TransformerBlock(\n",
              "        (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GenericSelfAttention(\n",
              "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (c_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): ModuleDict(\n",
              "          (c_fc): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (c_proj): Linear(in_features=256, out_features=64, bias=True)\n",
              "          (act): NewGELU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=64, out_features=258, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model, trainer = train(data, model_type=\"Decoder\",\n",
        "          learning_rate = 1e-3,\n",
        "          batch_size = 256,\n",
        "          max_iters = 10000,\n",
        "          dec_n_layer=4,\n",
        "          dec_n_embd=64,\n",
        "          dec_n_head =2,\n",
        "          enc_n_layer=None,\n",
        "          enc_n_embd=None,\n",
        "          enc_n_head=None)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LA77eMgfCsgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a869d3-f996-46e1-d687-57d4ec23568d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [02:26<00:00,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Exact Match: 85/100 = 85.00% correct\n",
            "BLEU = 100.00 100.0/100.0/100.0/100.0 (BP = 1.000 ratio = 1.000 hyp_len = 13 ref_len = 13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "def eval(trainer, data, tokenizer):\n",
        "    bleu = BLEU()\n",
        "    results = []\n",
        "    mistakes_printed_already = 0\n",
        "    tgts = []\n",
        "    cands = []\n",
        "    for sent in tqdm(data[10000:10100]):\n",
        "        inp = torch.tensor([tokenizer.encode(sent.split(\"[SEP]\")[0] + \"[SEP]\")])\n",
        "        tgt = bytes(sent.split(\"[SEP]\")[1].split(\"[END]\")[0], \"utf-8\")\n",
        "        cat = generate(model, inp, model.block_size-len(inp[0]), 0.1)\n",
        "        tgt_candidate = tokenizer.decode(cat.cpu().numpy()[0])\n",
        "        tgt_candidate = tgt_candidate.split(b\"[END]\")[0].split(b\"[SEP]\")[1]\n",
        "        # compare the predicted sequence to the true sequence\n",
        "        tgts.append([str(tgt)])\n",
        "        cands.append(str(tgt_candidate))\n",
        "        correct = (tgt == tgt_candidate)\n",
        "        results.append(correct)\n",
        "    results = torch.tensor(results).type(torch.float)\n",
        "    print(\"\\n\\nExact Match: %d/%d = %.2f%% correct\" % (torch.sum(results), len(results), 100*torch.mean(results)))\n",
        "    score = bleu.corpus_score(cands, tgts)\n",
        "    print(score)\n",
        "\n",
        "    return results\n",
        "\n",
        "with torch.no_grad():\n",
        "  results = eval(trainer, data, Tokenizer())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Assignment Export - Upload the `my_llm_implementation.py` file to GradeScope\n",
        "\n",
        "with open(\"./my_llm_implementation.py\", \"w\") as f:\n",
        "  f.write(setup_block.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(embedding_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(mha_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(block_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(transformer_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(encoder_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(decoder_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(generate_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(encdec_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(pref_generate_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "\n",
        "# If you decide to do this assignment not on Colab, you'll need to simply find the file\n",
        "from google.colab import files\n",
        "files.download('./my_llm_implementation.py')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1lWwrT4r3HGF",
        "outputId": "07408709-84d6-4c98-f829-95db93632261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0d2b52a1-08ff-44f0-81d5-2c1c953141cd\", \"my_llm_implementation.py\", 19017)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UI5J9d5uMGgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab380e0bb858470ab503ff3ddad94957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe1d76599ee743bca398a2e4c563dee9",
              "IPY_MODEL_15d9aa0aa3294897bdc1a73dfdf2f234",
              "IPY_MODEL_540aacf467be45e8ad1713b7db69fc93"
            ],
            "layout": "IPY_MODEL_4c74f1a40af04eaeadde16a121c13e14"
          }
        },
        "fe1d76599ee743bca398a2e4c563dee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_980f3312915f433093e77c181d29d736",
            "placeholder": "​",
            "style": "IPY_MODEL_6e0f01619ea747b083a6eba1001731a5",
            "value": "Downloading builder script: 100%"
          }
        },
        "15d9aa0aa3294897bdc1a73dfdf2f234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70b586584b6946d1a5190cee85a6b077",
            "max": 5210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da6e8cff11f14edd9c2caf2bdaad0f51",
            "value": 5210
          }
        },
        "540aacf467be45e8ad1713b7db69fc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0a0430a26945f29fa30527c8817de1",
            "placeholder": "​",
            "style": "IPY_MODEL_252d065da2594208ae72e1f79afb1e3d",
            "value": " 5.21k/5.21k [00:00&lt;00:00, 362kB/s]"
          }
        },
        "4c74f1a40af04eaeadde16a121c13e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980f3312915f433093e77c181d29d736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0f01619ea747b083a6eba1001731a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70b586584b6946d1a5190cee85a6b077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6e8cff11f14edd9c2caf2bdaad0f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d0a0430a26945f29fa30527c8817de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252d065da2594208ae72e1f79afb1e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b9641ffbeea4fd9b7e7b44bbf418f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a2fa93c3530497dac2f136b05ac5025",
              "IPY_MODEL_a5923a85182b4f2ba8c256307cef79e6",
              "IPY_MODEL_ad2f0c03784549ddafdbf3ec26d7bf8f"
            ],
            "layout": "IPY_MODEL_05eb98bbe28a4432ab286308e3cadb68"
          }
        },
        "1a2fa93c3530497dac2f136b05ac5025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_356d3085066d441a900c18973e58d939",
            "placeholder": "​",
            "style": "IPY_MODEL_fdb9241c3b2b4b00a1988feb09e718d3",
            "value": "Downloading readme: 100%"
          }
        },
        "a5923a85182b4f2ba8c256307cef79e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d8bf9e3d8854b52886acbb4a86a6b09",
            "max": 1336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bb117850b6a4cdf8b7f7c40b1d0dcc4",
            "value": 1336
          }
        },
        "ad2f0c03784549ddafdbf3ec26d7bf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4ce8aea0ad43d5a58773cb862c2157",
            "placeholder": "​",
            "style": "IPY_MODEL_806347dfe0654ee68a289d7c5303bfdc",
            "value": " 1.34k/1.34k [00:00&lt;00:00, 48.6kB/s]"
          }
        },
        "05eb98bbe28a4432ab286308e3cadb68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "356d3085066d441a900c18973e58d939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb9241c3b2b4b00a1988feb09e718d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d8bf9e3d8854b52886acbb4a86a6b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb117850b6a4cdf8b7f7c40b1d0dcc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c4ce8aea0ad43d5a58773cb862c2157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806347dfe0654ee68a289d7c5303bfdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41252545fcc042719cceedf84bdf649a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9aca05041600432580827c47f9f17969",
              "IPY_MODEL_bd53e273f33f4336b4259c9d9246024c",
              "IPY_MODEL_bb8ebd6f738143b1b75f6ba299419b51"
            ],
            "layout": "IPY_MODEL_aa822136eafd4d4c89741957264cfd2d"
          }
        },
        "9aca05041600432580827c47f9f17969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5c1a9ab71e424d8bae0a2783fdd1d8",
            "placeholder": "​",
            "style": "IPY_MODEL_7b8c70643dd74705a4be550247b32b36",
            "value": "Downloading data files: 100%"
          }
        },
        "bd53e273f33f4336b4259c9d9246024c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff577ad4ef24420b3ea6b604bcba853",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6c7382c800d430d8cfc3b6f4dafe15c",
            "value": 2
          }
        },
        "bb8ebd6f738143b1b75f6ba299419b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59e135b41fd4a16b8a8c0be6a1e1c8b",
            "placeholder": "​",
            "style": "IPY_MODEL_c864227f8dae4c949c2d312a5a493206",
            "value": " 2/2 [00:06&lt;00:00,  2.97s/it]"
          }
        },
        "aa822136eafd4d4c89741957264cfd2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5c1a9ab71e424d8bae0a2783fdd1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b8c70643dd74705a4be550247b32b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ff577ad4ef24420b3ea6b604bcba853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c7382c800d430d8cfc3b6f4dafe15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a59e135b41fd4a16b8a8c0be6a1e1c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c864227f8dae4c949c2d312a5a493206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2333a6d74a5d4140a82550c034ad3149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4f15e353e2f46c6bfed7f203b85375b",
              "IPY_MODEL_3b7b53a50443455ba26cab604b4c6397",
              "IPY_MODEL_0208fd531c2a4ad69f21d07647c330c2"
            ],
            "layout": "IPY_MODEL_46e0f469deac43c7a109038680505104"
          }
        },
        "e4f15e353e2f46c6bfed7f203b85375b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f813057c05486f996cfbd1fdebcabc",
            "placeholder": "​",
            "style": "IPY_MODEL_b057ec34f47446e3a79cd0b301c71dbc",
            "value": "Downloading data: 100%"
          }
        },
        "3b7b53a50443455ba26cab604b4c6397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c08d9724286d411cabe0a59b128490b6",
            "max": 2495681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92260cf94d7b4952bbe154a9fe1995b8",
            "value": 2495681
          }
        },
        "0208fd531c2a4ad69f21d07647c330c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd37b32c461b45c3b84e184b14f77949",
            "placeholder": "​",
            "style": "IPY_MODEL_a897c3ef92824843b247bbabf79c2721",
            "value": " 2.50M/2.50M [00:01&lt;00:00, 2.54MB/s]"
          }
        },
        "46e0f469deac43c7a109038680505104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f813057c05486f996cfbd1fdebcabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b057ec34f47446e3a79cd0b301c71dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c08d9724286d411cabe0a59b128490b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92260cf94d7b4952bbe154a9fe1995b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd37b32c461b45c3b84e184b14f77949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a897c3ef92824843b247bbabf79c2721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fabe9b4e2884cd2ba046f48e8cfc19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67b9eb35dfdf44af9b2097b4ad3da2a8",
              "IPY_MODEL_fa8d658f3d22496b89ae083569fbd2a8",
              "IPY_MODEL_26772ae140e94adfa3ffa673fb4dd808"
            ],
            "layout": "IPY_MODEL_57eb8f849ae54f70a60291710ca77a53"
          }
        },
        "67b9eb35dfdf44af9b2097b4ad3da2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b85b7f592f3c4af59db37c4168fb2eea",
            "placeholder": "​",
            "style": "IPY_MODEL_67b3f743f0d84eae8f7bee6112787fb0",
            "value": "Downloading data: 100%"
          }
        },
        "fa8d658f3d22496b89ae083569fbd2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74f01fe58e224b4fb3915fff7381fc7b",
            "max": 188022,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2161b200ed044cd0bec9fce48dc8e8ec",
            "value": 188022
          }
        },
        "26772ae140e94adfa3ffa673fb4dd808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9436483acf4b31bdb144b1b28f597c",
            "placeholder": "​",
            "style": "IPY_MODEL_179c09ff627e4402a21cae067f15ca08",
            "value": " 188k/188k [00:00&lt;00:00, 223kB/s]"
          }
        },
        "57eb8f849ae54f70a60291710ca77a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85b7f592f3c4af59db37c4168fb2eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b3f743f0d84eae8f7bee6112787fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74f01fe58e224b4fb3915fff7381fc7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2161b200ed044cd0bec9fce48dc8e8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c9436483acf4b31bdb144b1b28f597c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179c09ff627e4402a21cae067f15ca08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99cc2a7b3dd24407a9ca633602e9fac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a66ede6d201c423e9105aa18e305875f",
              "IPY_MODEL_93e7e836e6c54c58ae235f6f0e62bfa0",
              "IPY_MODEL_9140f6fa03df42fa802130637aa412ee"
            ],
            "layout": "IPY_MODEL_67142d2f66394d14894fecd0d64d7b7c"
          }
        },
        "a66ede6d201c423e9105aa18e305875f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18dde0b58732418fb1bf9f959ed77323",
            "placeholder": "​",
            "style": "IPY_MODEL_22863eb832774b89bfa1fe467228751b",
            "value": "Extracting data files: 100%"
          }
        },
        "93e7e836e6c54c58ae235f6f0e62bfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d42d487d7ce242f786790dbca1044b05",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95cbbb22f8d948d394fde80a03271e58",
            "value": 2
          }
        },
        "9140f6fa03df42fa802130637aa412ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b41a93939a4bd0a8f63365bc21253c",
            "placeholder": "​",
            "style": "IPY_MODEL_bbfb6384cb0f427f87e82fcbfd97c4c3",
            "value": " 2/2 [00:00&lt;00:00, 84.58it/s]"
          }
        },
        "67142d2f66394d14894fecd0d64d7b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18dde0b58732418fb1bf9f959ed77323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22863eb832774b89bfa1fe467228751b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d42d487d7ce242f786790dbca1044b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95cbbb22f8d948d394fde80a03271e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50b41a93939a4bd0a8f63365bc21253c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbfb6384cb0f427f87e82fcbfd97c4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d21ffd70ef44eb6a8ea6434bebcfeda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3cd4e87bf964c41bf9b2f470b21384f",
              "IPY_MODEL_ab2e7453b49e4c30ba7ed85b71ec9a4d",
              "IPY_MODEL_93d89c158d06428ca321c6a7e557dbd0"
            ],
            "layout": "IPY_MODEL_818253ed0ef940b49b74fd9ed27fc6d2"
          }
        },
        "d3cd4e87bf964c41bf9b2f470b21384f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbfb129277c744249aaed8fe88b660bc",
            "placeholder": "​",
            "style": "IPY_MODEL_345f637515154597949949b26251a6a7",
            "value": "Generating train split: "
          }
        },
        "ab2e7453b49e4c30ba7ed85b71ec9a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f98bfd4de3104f52a82b47ae821ec7c3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ba149b45ede4a8fb89abeca5f41f362",
            "value": 1
          }
        },
        "93d89c158d06428ca321c6a7e557dbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e72b078abdd4da09a496cdb47f33742",
            "placeholder": "​",
            "style": "IPY_MODEL_d70431167bf14a5aa359ed517ef53364",
            "value": " 13232/0 [00:00&lt;00:00, 32462.31 examples/s]"
          }
        },
        "818253ed0ef940b49b74fd9ed27fc6d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfb129277c744249aaed8fe88b660bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345f637515154597949949b26251a6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f98bfd4de3104f52a82b47ae821ec7c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7ba149b45ede4a8fb89abeca5f41f362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e72b078abdd4da09a496cdb47f33742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70431167bf14a5aa359ed517ef53364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0c7c062a75c4e71b0beb07056454594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb0adb06cf544f048f5a9ceaf2e80bc9",
              "IPY_MODEL_42364ee2e1c04ff6954ec3abda569cce",
              "IPY_MODEL_a019c62bd2124dd6abf655e793746f60"
            ],
            "layout": "IPY_MODEL_44982efe57694741bd582ce55705468a"
          }
        },
        "bb0adb06cf544f048f5a9ceaf2e80bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b2d185a9f441e081166e8d79ad29ba",
            "placeholder": "​",
            "style": "IPY_MODEL_529cac0d5b72494083262d5cc77ecf26",
            "value": "Generating validation split: "
          }
        },
        "42364ee2e1c04ff6954ec3abda569cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abfeb4cbc8c4487b8b8a8d58b1bc3d35",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2cce30979594e6b865f957b71e1723f",
            "value": 1
          }
        },
        "a019c62bd2124dd6abf655e793746f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6dd04277a745849cf1d4083cc70f87",
            "placeholder": "​",
            "style": "IPY_MODEL_86f4c0ad8cdb48dfbd710889022d3d7b",
            "value": " 1000/0 [00:00&lt;00:00, 12913.97 examples/s]"
          }
        },
        "44982efe57694741bd582ce55705468a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23b2d185a9f441e081166e8d79ad29ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529cac0d5b72494083262d5cc77ecf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abfeb4cbc8c4487b8b8a8d58b1bc3d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c2cce30979594e6b865f957b71e1723f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c6dd04277a745849cf1d4083cc70f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f4c0ad8cdb48dfbd710889022d3d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "948f73c94f974114ade716e1b760a5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8984039dc38d4850bdf6a0faf1188985",
              "IPY_MODEL_decdd945c06442a9a7ff75093bc594dc",
              "IPY_MODEL_f7d9c9ce51ad4bec8a6f071f06042acd"
            ],
            "layout": "IPY_MODEL_532698df74c74b86bb5d938984d786c9"
          }
        },
        "8984039dc38d4850bdf6a0faf1188985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da10b04bf4a479d9446ee618c976d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7f1151224d4b7a841f104417d24f44",
            "value": "Map: 100%"
          }
        },
        "decdd945c06442a9a7ff75093bc594dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a086048db4c84528853dfe270f99d02a",
            "max": 13232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8d430f7dd98412c868f756c0bf71a20",
            "value": 13232
          }
        },
        "f7d9c9ce51ad4bec8a6f071f06042acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd9ae31cffc9474b88b2c4e5743bd0f1",
            "placeholder": "​",
            "style": "IPY_MODEL_b6bdfc673750491799ad6ec7c3cc0cab",
            "value": " 13232/13232 [00:00&lt;00:00, 23083.85 examples/s]"
          }
        },
        "532698df74c74b86bb5d938984d786c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da10b04bf4a479d9446ee618c976d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7f1151224d4b7a841f104417d24f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a086048db4c84528853dfe270f99d02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d430f7dd98412c868f756c0bf71a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd9ae31cffc9474b88b2c4e5743bd0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6bdfc673750491799ad6ec7c3cc0cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}